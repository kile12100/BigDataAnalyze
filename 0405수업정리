이번 수업에서는 간단하게 이전 시간에 배웠던 선형변환을 통해서 고윳값과 고유벡터를 구하는 과정과 수식의 정리를 복습했으며,
이후 공분산 행렬과 선형변환 시의 특징을 배웠고, 마지막으로 실제 데이터 분석의 사례를 코드와 함께 배우는 시간을 가졌다.

우선 선형변환을 통해 고윳값과 고유벡터를 구하는 과정은 이전에도 했기 때문에 생략하겠다.

공분산을 먼저 설명하자면 여러 개의 집단값들의 상관관계라고 보면 되겠다.
공식으로는 Cov(x,y,,,) = E(xi - x\)(yi - y\)().../N가 된다.
우리가 일반적인 통계에서는 서로 척도(기준, 단위)가 다른 자료들을 사용할 때, 각 값들의 상관관계를 파악해야하는데
그럴 때 표준화를 거친 후 적용하는 경우가 있다. 많이들 들어본 표준정규분포표도 표준화를 거친 후 표로 나타낸 것으로
이러한 작업을 거치면서 여러 척도의 값들을 서로 상관관계에 맞게끔 값들을 조정해서 적용시킬 수 있다.
이를 데이터분석에서 활용하기 위해선 공분산을 이용한 공분산행렬에서 선형변환작업을 거치는 것이다.

이렇게 공분산 행렬을 선형변환작업을 거치게 된다면, 고유벡터와 고윳값을 구하면서 차원축소과정이 일어나고 오버피팅현상을 막는다는 특징이 있다.
오버피팅이란, 너무 많은 자료들로 인해서 오히려 데이터분석에 있어서 오류가 발생하는 것을 말한다.
예를 든다면, 우리가 자동차의 성능을 비교하려고 할 때 주어진 자료에서 필요한 것들만 모아서 분석하면 되는데
수집된 자료항목에 만약에 가격이나, 차의 색깔 같은 성능과 관련없는 자료가 모인다면 어떻게 될까?

우리고 도출하고자하는 결과에 영향이 안미치거나 오히려 도출하는 과정에서 방해가 될 수 있다.
이러한 예시가 오버피팅을 잘보여주는 예시라고 할 수 있다.

정리해서 공분산행렬의 선형변환 작업을 통해 오버피팅을 방지하고 차원축소를 거치게 된다면
그래프 상에서 이런 자료수집현황을 볼 때, 크게 한 가지 또는 두 개의 주요 축을 볼 수 있다.
이러한 축이 주성분 또는 주축이라고 부르며 고유값이 제일 큰값이 제일 큰범위로 나타내는 것이라고 볼 수 있다.

예시를 들자면 학생의 신체정보로 키, 나이, 몸무게를 수집했다고 하자.
여기서 세 가지 항목의 자료를 신체수치라는 값으로 묶어서 나타내고싶다면
선형변환을 통해 주성분을 찾고 그 주성분을 축으로 정해서 신체수치를 1차원으로 볼 수 있게 된다.

이렇게 그동안 선형변환에 대해서 중요성과 필요성을 계속해서 배우게 됐다.

이후에 이를 실제 파이썬으로 간단하게 고윳값과 고유벡터를 구하는 시간도 가져봤다.

import numpy as np

#행렬 A 정의
a = np.array([[2,4],[5,3]])

#고유값 고유벡터 계산
np.linalg.eig(a)

e_value, e_vect = np.linalg.eig(a)
print('고유값',e_value) 
print('고유벡터\n',e_vect)


우선 기본적으로 행렬을 표현하고 계산을 하기 위해선 파이썬에서 numpy패키지를 가져오는 과정을 거쳐야하며
행렬을 정해준다면, linalg.eig 로 고유값과 고유벡터 값이 나오게 된다.

이후 교수님께서 직접 보여주신 실제 데이터 분석 코드를 보는 시간을 가졌는데,
간단하게 요약하면 과일 사진들을 데이터로 수집해서 픽셀단위로 쪼개서 학습을 하고
이후에 학습한 데이터들을 선형변환을 통해 300장의 사진에 100픽셀로 쪼갠 것을
50개로 차원축소했고, 그 이후 축소한 데이터들로 다시 사진들로 재구성하는 과정을 거쳤다.
놀랍게도 과도하게 차원을 축소한다면 유사율이 떨어지지만 특정 차원축소부터는
크게 차이가 없다는 사실을 확인할 수 있었고, 이로 인해서 효율적으로 데이터를 압축해서
최소한의 데이터수집과 분석과정으로 최대한의 효율을 나타내는 것이 중요하다는 것을 배우는 시간 또한 배웠다.
